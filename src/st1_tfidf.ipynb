{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sub-task 1 with Tf-Idf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run import_data.ipynb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "from utils.evaluation import evaluate_pipeline_x_validation, evaluate_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a TF-IDF pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# creating a pipeline to run on each classifier.\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', ClfSwitcher())\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Experiences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Native Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:17<00:00,  4.33s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1-micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unbalanced1</td>\n",
       "      <td>0.355818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unbalanced2</td>\n",
       "      <td>0.340811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>balanced1</td>\n",
       "      <td>0.322801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>balanced2</td>\n",
       "      <td>0.281471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model  f1-micro\n",
       "0  unbalanced1  0.355818\n",
       "1  unbalanced2  0.340811\n",
       "2    balanced1  0.322801\n",
       "3    balanced2  0.281471"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weigth = [None,'balanced']\n",
    "\n",
    "estimators = [DecisionTreeClassifier(class_weight=weigth) for weigth in class_weigth]\n",
    "\n",
    "grid = ParameterGrid({\n",
    "    'clf__estimator': estimators,\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)],\n",
    "})\n",
    "\n",
    "models = ['unbalanced1', 'unbalanced2', 'balanced1', 'balanced2']\n",
    "\n",
    "evaluate_pipeline_x_validation(pipeline, grid, models, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1-score for Model is 0.3062381852551985\n",
      "Macro F1-score for Model is 0.1333930741713458\n",
      "Time to train the model: 0.681833028793335 seconds\n",
      "F1-Score for Model is [0.         0.         0.         0.4        0.         0.05263158\n",
      " 0.32       0.4        0.15384615 0.46428571 0.         0.30434783\n",
      " 0.         0.         0.         0.         0.20689655 0.36585366\n",
      " 0.         0.        ]\n",
      "Precision for Model is [0.         0.         0.         0.66666667 0.         0.1\n",
      " 0.66666667 0.5        0.5        0.57352941 0.         0.35897436\n",
      " 0.         0.         0.         0.         0.3        0.40540541\n",
      " 0.         0.        ]\n",
      "Recall for Model is [0.         0.         0.         0.28571429 0.         0.03571429\n",
      " 0.21052632 0.33333333 0.09090909 0.39       0.         0.26415094\n",
      " 0.         0.         0.         0.         0.15789474 0.33333333\n",
      " 0.         0.        ]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(grid[1], X_train, y_train, X_test, y_test, pipeline)\n",
    "\n",
    "\n",
    "# decision_tree_best = grid[1]\n",
    "\n",
    "# pipeline.set_params(**decision_tree_best)\n",
    "# pipeline.fit(X_train, y_train)\n",
    "# y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# print(f\"F1-micro score for DecisionTree is {f1_score(y_test, y_pred, average='micro', zero_division=0)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:10<00:00,  1.29s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1-micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExtraMaxNone_1</td>\n",
       "      <td>0.348878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraMaxNone_2</td>\n",
       "      <td>0.353491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraMax5_1</td>\n",
       "      <td>0.320666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraMax5_2</td>\n",
       "      <td>0.267447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraMax10_1</td>\n",
       "      <td>0.288723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraMax10_2</td>\n",
       "      <td>0.238999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraMax20_1</td>\n",
       "      <td>0.331170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraMax20_2</td>\n",
       "      <td>0.238757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model  f1-micro\n",
       "0  ExtraMaxNone_1  0.348878\n",
       "1  ExtraMaxNone_2  0.353491\n",
       "2     ExtraMax5_1  0.320666\n",
       "3     ExtraMax5_2  0.267447\n",
       "4    ExtraMax10_1  0.288723\n",
       "5    ExtraMax10_2  0.238999\n",
       "6    ExtraMax20_1  0.331170\n",
       "7    ExtraMax20_2  0.238757"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = [None,5,10,20]\n",
    "\n",
    "estimators = [ExtraTreeClassifier(max_features=feat) for feat in max_features]\n",
    "\n",
    "grid = ParameterGrid({\n",
    "    'clf__estimator': estimators,\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)]\n",
    "})\n",
    "\n",
    "models = ['ExtraMaxNone_1', 'ExtraMaxNone_2', 'ExtraMax5_1', 'ExtraMax5_2', 'ExtraMax10_1', 'ExtraMax10_2', 'ExtraMax20_1', 'ExtraMax20_2']\n",
    "\n",
    "evaluate_pipeline_x_validation(pipeline, grid, models, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1-score for Model is 0.31721470019342357\n",
      "Macro F1-score for Model is 0.12563874135001102\n",
      "Time to train the model: 0.7024452686309814 seconds\n",
      "F1-Score for Model is [0.22222222 0.13333333 0.         0.2        0.         0.09302326\n",
      " 0.24       0.28571429 0.         0.51898734 0.         0.43478261\n",
      " 0.         0.         0.         0.         0.0952381  0.28947368\n",
      " 0.         0.        ]\n",
      "Precision for Model is [0.5        0.2        0.         0.33333333 0.         0.13333333\n",
      " 0.5        1.         0.         0.70689655 0.         0.51282051\n",
      " 0.         0.         0.         0.         0.5        0.35483871\n",
      " 0.         0.        ]\n",
      "Recall for Model is [0.14285714 0.1        0.         0.14285714 0.         0.07142857\n",
      " 0.15789474 0.16666667 0.         0.41       0.         0.37735849\n",
      " 0.         0.         0.         0.         0.05263158 0.24444444\n",
      " 0.         0.        ]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(grid[1], X_train, y_train, X_test, y_test, pipeline)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1-micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Knn5_1</td>\n",
       "      <td>0.221464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Knn5_2</td>\n",
       "      <td>0.224927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Knn10_1</td>\n",
       "      <td>0.188846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Knn10_2</td>\n",
       "      <td>0.209631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Knn20_1</td>\n",
       "      <td>0.224322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Knn20_2</td>\n",
       "      <td>0.230266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Knn50_1</td>\n",
       "      <td>0.287433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Knn50_2</td>\n",
       "      <td>0.285693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  f1-micro\n",
       "0   Knn5_1  0.221464\n",
       "1   Knn5_2  0.224927\n",
       "2  Knn10_1  0.188846\n",
       "3  Knn10_2  0.209631\n",
       "4  Knn20_1  0.224322\n",
       "5  Knn20_2  0.230266\n",
       "6  Knn50_1  0.287433\n",
       "7  Knn50_2  0.285693"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neighbors = [5,10,20,50]\n",
    "\n",
    "estimators = [KNeighborsClassifier(n_neighbors=n) for n in n_neighbors]\n",
    "\n",
    "grid = ParameterGrid({\n",
    "    'clf__estimator': estimators,\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)]\n",
    "})\n",
    "\n",
    "models = ['Knn5_1', 'Knn5_2', 'Knn10_1', 'Knn10_2', 'Knn20_1', 'Knn20_2', 'Knn50_1', 'Knn50_2']\n",
    "\n",
    "evaluate_pipeline_x_validation(pipeline, grid, models, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1-score for Model is 0.2033898305084746\n",
      "Macro F1-score for Model is 0.047254156100309946\n",
      "Time to train the model: 0.17951107025146484 seconds\n",
      "F1-Score for Model is [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.28571429 0.         0.4260355  0.         0.13333333\n",
      " 0.         0.         0.         0.         0.1        0.\n",
      " 0.         0.        ]\n",
      "Precision for Model is [0.         0.         0.         0.         0.         0.\n",
      " 0.         1.         0.         0.52173913 0.         0.57142857\n",
      " 0.         0.         0.         0.         1.         0.\n",
      " 0.         0.        ]\n",
      "Recall for Model is [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.16666667 0.         0.36       0.         0.0754717\n",
      " 0.         0.         0.         0.         0.05263158 0.\n",
      " 0.         0.        ]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(grid[5], X_train, y_train, X_test, y_test, pipeline)\n",
    "# knn_best = grid[5]\n",
    "\n",
    "# pipeline.set_params(**knn_best)\n",
    "# pipeline.fit(X_train, y_train)\n",
    "# y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# print(f\"F1-micro score for KNN is {f1_score(y_test, y_pred, average='micro', zero_division=0)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [04:29<00:00, 33.65s/it] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1-micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m1</td>\n",
       "      <td>0.362056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m2</td>\n",
       "      <td>0.344683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m3</td>\n",
       "      <td>0.342012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m4</td>\n",
       "      <td>0.320272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m5</td>\n",
       "      <td>0.232035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>m6</td>\n",
       "      <td>0.226615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>m7</td>\n",
       "      <td>0.354912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>m8</td>\n",
       "      <td>0.361617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  f1-micro\n",
       "0    m1  0.362056\n",
       "1    m2  0.344683\n",
       "2    m3  0.342012\n",
       "3    m4  0.320272\n",
       "4    m5  0.232035\n",
       "5    m6  0.226615\n",
       "6    m7  0.354912\n",
       "7    m8  0.361617"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "classifier = [BinaryRelevance(classifier = DecisionTreeClassifier()),\n",
    "              BinaryRelevance(classifier = ExtraTreeClassifier()),\n",
    "              BinaryRelevance(classifier = KNeighborsClassifier(n_neighbors=20)),\n",
    "              BinaryRelevance(classifier = GaussianNB())]\n",
    "\n",
    "grid = ParameterGrid({\n",
    "    'clf__estimator': classifier,\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)]\n",
    "})\n",
    "\n",
    "models = ['m1', 'm2', 'm3', 'm4', 'm5', 'm6', 'm7', 'm8']\n",
    "\n",
    "evaluate_pipeline_x_validation(pipeline, grid, models, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1-score for Model is 0.314785373608903\n",
      "Macro F1-score for Model is 0.12575030418533442\n",
      "Time to train the model: 5.13608193397522 seconds\n",
      "F1-Score for Model is [0.2        0.         0.         0.18181818 0.18181818 0.1025641\n",
      " 0.125      0.14285714 0.         0.57627119 0.         0.3853211\n",
      " 0.         0.         0.         0.         0.0625     0.32608696\n",
      " 0.         0.23076923]\n",
      "Precision for Model is [0.33333333 0.         0.         0.25       0.125      0.18181818\n",
      " 0.15384615 0.125      0.         0.66233766 0.         0.375\n",
      " 0.         0.         0.         0.         0.07692308 0.31914894\n",
      " 0.         0.1875    ]\n",
      "Recall for Model is [0.14285714 0.         0.         0.14285714 0.33333333 0.07142857\n",
      " 0.10526316 0.16666667 0.         0.51       0.         0.39622642\n",
      " 0.         0.         0.         0.         0.05263158 0.33333333\n",
      " 0.         0.3       ]\n",
      "\n",
      "\n",
      "Micro F1-score for Model is 0.29965156794425085\n",
      "Macro F1-score for Model is 0.1306816427620184\n",
      "Time to train the model: 25.663768768310547 seconds\n",
      "F1-Score for Model is [0.16666667 0.11111111 0.         0.22222222 0.25       0.10526316\n",
      " 0.36363636 0.18181818 0.         0.49101796 0.         0.35514019\n",
      " 0.         0.         0.         0.         0.07407407 0.29268293\n",
      " 0.         0.        ]\n",
      "Precision for Model is [0.2        0.125      0.         0.5        0.2        0.2\n",
      " 0.42857143 0.2        0.         0.6119403  0.         0.35185185\n",
      " 0.         0.         0.         0.         0.125      0.32432432\n",
      " 0.         0.        ]\n",
      "Recall for Model is [0.14285714 0.1        0.         0.14285714 0.33333333 0.07142857\n",
      " 0.31578947 0.16666667 0.         0.41       0.         0.35849057\n",
      " 0.         0.         0.         0.         0.05263158 0.26666667\n",
      " 0.         0.        ]\n",
      "\n",
      "\n",
      "Micro F1-score for Model is 0.3333333333333333\n",
      "Macro F1-score for Model is 0.14669495596663068\n",
      "Time to train the model: 0.329268217086792 seconds\n",
      "F1-Score for Model is [0.16666667 0.         0.         0.18181818 0.25       0.11111111\n",
      " 0.29411765 0.18181818 0.26666667 0.60571429 0.         0.2970297\n",
      " 0.         0.         0.         0.         0.13793103 0.30769231\n",
      " 0.         0.13333333]\n",
      "Precision for Model is [0.2        0.         0.         0.25       0.2        0.25\n",
      " 0.33333333 0.2        0.5        0.70666667 0.         0.3125\n",
      " 0.         0.         0.         0.         0.2        0.36363636\n",
      " 0.         0.2       ]\n",
      "Recall for Model is [0.14285714 0.         0.         0.14285714 0.33333333 0.07142857\n",
      " 0.26315789 0.16666667 0.18181818 0.53       0.         0.28301887\n",
      " 0.         0.         0.         0.         0.10526316 0.26666667\n",
      " 0.         0.1       ]\n",
      "\n",
      "\n",
      "Micro F1-score for Model is 0.2828282828282829\n",
      "Macro F1-score for Model is 0.0958630172759071\n",
      "Time to train the model: 1.4266319274902344 seconds\n",
      "F1-Score for Model is [0.         0.         0.         0.         0.         0.15\n",
      " 0.08333333 0.         0.31578947 0.46052632 0.         0.39534884\n",
      " 0.         0.         0.         0.         0.07692308 0.25352113\n",
      " 0.         0.18181818]\n",
      "Precision for Model is [0.         0.         0.         0.         0.         0.25\n",
      " 0.2        0.         0.375      0.67307692 0.         0.51515152\n",
      " 0.         0.         0.         0.         0.14285714 0.34615385\n",
      " 0.         1.        ]\n",
      "Recall for Model is [0.         0.         0.         0.         0.         0.10714286\n",
      " 0.05263158 0.         0.27272727 0.35       0.         0.32075472\n",
      " 0.         0.         0.         0.         0.05263158 0.2\n",
      " 0.         0.1       ]\n",
      "\n",
      "\n",
      "Micro F1-score for Model is 0.1773399014778325\n",
      "Macro F1-score for Model is 0.031189041881812967\n",
      "Time to train the model: 0.5185096263885498 seconds\n",
      "F1-Score for Model is [0.         0.         0.         0.         0.         0.\n",
      " 0.19047619 0.         0.         0.39759036 0.         0.03571429\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "Precision for Model is [0.         0.         0.         0.         0.         0.\n",
      " 1.         0.         0.         0.5        0.         0.33333333\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "Recall for Model is [0.         0.         0.         0.         0.         0.\n",
      " 0.10526316 0.         0.         0.33       0.         0.01886792\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "\n",
      "\n",
      "Micro F1-score for Model is 0.1897810218978102\n",
      "Macro F1-score for Model is 0.04369207398011858\n",
      "Time to train the model: 1.3007826805114746 seconds\n",
      "F1-Score for Model is [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.28571429 0.         0.41916168 0.         0.06896552\n",
      " 0.         0.         0.         0.         0.1        0.\n",
      " 0.         0.        ]\n",
      "Precision for Model is [0.         0.         0.         0.         0.         0.\n",
      " 0.         1.         0.         0.52238806 0.         0.4\n",
      " 0.         0.         0.         0.         1.         0.\n",
      " 0.         0.        ]\n",
      "Recall for Model is [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.16666667 0.         0.35       0.         0.03773585\n",
      " 0.         0.         0.         0.         0.05263158 0.\n",
      " 0.         0.        ]\n",
      "\n",
      "\n",
      "Micro F1-score for Model is 0.2969325153374234\n",
      "Macro F1-score for Model is 0.08231966392915889\n",
      "Time to train the model: 0.5390636920928955 seconds\n",
      "F1-Score for Model is [0.         0.         0.         0.         0.         0.\n",
      " 0.05128205 0.         0.         0.65686275 0.         0.36708861\n",
      " 0.         0.         0.         0.         0.24242424 0.26206897\n",
      " 0.         0.06666667]\n",
      "Precision for Model is [0.         0.         0.         0.         0.         0.\n",
      " 0.05       0.         0.         0.64423077 0.         0.27619048\n",
      " 0.         0.         0.         0.         0.28571429 0.19\n",
      " 0.         0.05      ]\n",
      "Recall for Model is [0.         0.         0.         0.         0.         0.\n",
      " 0.05263158 0.         0.         0.67       0.         0.54716981\n",
      " 0.         0.         0.         0.         0.21052632 0.42222222\n",
      " 0.         0.1       ]\n",
      "\n",
      "\n",
      "Micro F1-score for Model is 0.3015463917525773\n",
      "Macro F1-score for Model is 0.0861191472758637\n",
      "Time to train the model: 4.521575450897217 seconds\n",
      "F1-Score for Model is [0.14285714 0.         0.         0.         0.         0.\n",
      " 0.05714286 0.         0.         0.67307692 0.         0.35135135\n",
      " 0.         0.         0.         0.         0.2        0.2238806\n",
      " 0.         0.07407407]\n",
      "Precision for Model is [0.14285714 0.         0.         0.         0.         0.\n",
      " 0.0625     0.         0.         0.64814815 0.         0.27368421\n",
      " 0.         0.         0.         0.         0.27272727 0.16853933\n",
      " 0.         0.05882353]\n",
      "Recall for Model is [0.14285714 0.         0.         0.         0.         0.\n",
      " 0.05263158 0.         0.         0.7        0.         0.49056604\n",
      " 0.         0.         0.         0.         0.15789474 0.33333333\n",
      " 0.         0.1       ]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, params in enumerate(grid, start=1):\n",
    "   evaluate_model(params, X_train, y_train, X_test, y_test, pipeline) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1-score for Model is 0.3032629558541267\n",
      "Macro F1-score for Model is 0.09133697283235588\n",
      "Time to train the model: 1.536299467086792 seconds\n",
      "F1-Score for Model is [0.         0.         0.         0.         0.         0.0625\n",
      " 0.2962963  0.14285714 0.16666667 0.51162791 0.         0.34090909\n",
      " 0.         0.         0.         0.         0.         0.30588235\n",
      " 0.         0.        ]\n",
      "Precision for Model is [0.         0.         0.         0.         0.         0.25\n",
      " 0.5        0.125      1.         0.61111111 0.         0.42857143\n",
      " 0.         0.         0.         0.         0.         0.325\n",
      " 0.         0.        ]\n",
      "Recall for Model is [0.         0.         0.         0.         0.         0.03571429\n",
      " 0.21052632 0.16666667 0.09090909 0.44       0.         0.28301887\n",
      " 0.         0.         0.         0.         0.         0.28888889\n",
      " 0.         0.        ]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is the evaluation for Binary Relevance extra tree classifier\n",
    "evaluate_model(grid[3], X_train, y_train, X_test, y_test, pipeline) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Powerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:42<00:00,  7.17s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1-micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m1</td>\n",
       "      <td>0.313981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m2</td>\n",
       "      <td>0.306471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m3</td>\n",
       "      <td>0.122191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m4</td>\n",
       "      <td>0.113881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m5</td>\n",
       "      <td>0.365972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>m6</td>\n",
       "      <td>0.375218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  f1-micro\n",
       "0    m1  0.313981\n",
       "1    m2  0.306471\n",
       "2    m3  0.122191\n",
       "3    m4  0.113881\n",
       "4    m5  0.365972\n",
       "5    m6  0.375218"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = [LabelPowerset(classifier = DecisionTreeClassifier()),\n",
    "              LabelPowerset(classifier = KNeighborsClassifier(n_neighbors=20)),\n",
    "              LabelPowerset(classifier = GaussianNB())]\n",
    "\n",
    "grid = ParameterGrid({\n",
    "    'clf__estimator': classifier,\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)]\n",
    "})\n",
    "\n",
    "\n",
    "models = ['m1', 'm2', 'm3', 'm4', 'm5', 'm6']\n",
    "\n",
    "evaluate_pipeline_x_validation(pipeline, grid, models, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1-score for Model is 0.32098765432098764\n",
      "Macro F1-score for Model is 0.11734563641226259\n",
      "Time to train the model: 0.8674914836883545 seconds\n",
      "F1-Score for Model is [0.         0.11111111 0.         0.         0.         0.\n",
      " 0.35294118 0.30769231 0.15384615 0.5698324  0.         0.28865979\n",
      " 0.         0.         0.         0.         0.14285714 0.30232558\n",
      " 0.         0.11764706]\n",
      "Precision for Model is [0.         0.125      0.         0.         0.         0.\n",
      " 0.4        0.28571429 0.5        0.64556962 0.         0.31818182\n",
      " 0.         0.         0.         0.         0.22222222 0.31707317\n",
      " 0.         0.14285714]\n",
      "Recall for Model is [0.         0.1        0.         0.         0.         0.\n",
      " 0.31578947 0.33333333 0.09090909 0.51       0.         0.26415094\n",
      " 0.         0.         0.         0.         0.10526316 0.28888889\n",
      " 0.         0.1       ]\n",
      "\n",
      "\n",
      "Micro F1-score for Model is 0.25868725868725867\n",
      "Macro F1-score for Model is 0.08520305003063623\n",
      "Time to train the model: 3.2849438190460205 seconds\n",
      "F1-Score for Model is [0.         0.         0.         0.         0.         0.05714286\n",
      " 0.13793103 0.18181818 0.         0.47435897 0.         0.31111111\n",
      " 0.         0.         0.         0.         0.07142857 0.27027027\n",
      " 0.2        0.        ]\n",
      "Precision for Model is [0.         0.         0.         0.         0.         0.14285714\n",
      " 0.2        0.2        0.         0.66071429 0.         0.37837838\n",
      " 0.         0.         0.         0.         0.11111111 0.34482759\n",
      " 0.25       0.        ]\n",
      "Recall for Model is [0.         0.         0.         0.         0.         0.03571429\n",
      " 0.10526316 0.16666667 0.         0.37       0.         0.26415094\n",
      " 0.         0.         0.         0.         0.05263158 0.22222222\n",
      " 0.16666667 0.        ]\n",
      "\n",
      "\n",
      "Micro F1-score for Model is 0.11671087533156498\n",
      "Macro F1-score for Model is 0.029242194904729218\n",
      "Time to train the model: 0.055496931076049805 seconds\n",
      "F1-Score for Model is [0.         0.         0.         0.         0.         0.\n",
      " 0.19047619 0.         0.         0.25806452 0.         0.09375\n",
      " 0.         0.         0.         0.         0.         0.04255319\n",
      " 0.         0.        ]\n",
      "Precision for Model is [0.         0.         0.         0.         0.         0.\n",
      " 1.         0.         0.         0.66666667 0.         0.27272727\n",
      " 0.         0.         0.         0.         0.         0.5\n",
      " 0.         0.        ]\n",
      "Recall for Model is [0.         0.         0.         0.         0.         0.\n",
      " 0.10526316 0.         0.         0.16       0.         0.05660377\n",
      " 0.         0.         0.         0.         0.         0.02222222\n",
      " 0.         0.        ]\n",
      "\n",
      "\n",
      "Micro F1-score for Model is 0.12041884816753926\n",
      "Macro F1-score for Model is 0.028952104097452934\n",
      "Time to train the model: 0.1048886775970459 seconds\n",
      "F1-Score for Model is [0.         0.         0.         0.         0.         0.\n",
      " 0.19047619 0.         0.         0.26356589 0.         0.125\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "Precision for Model is [0.         0.         0.         0.         0.         0.\n",
      " 1.         0.         0.         0.5862069  0.         0.36363636\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "Recall for Model is [0.         0.         0.         0.         0.         0.\n",
      " 0.10526316 0.         0.         0.17       0.         0.0754717\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "\n",
      "\n",
      "Micro F1-score for Model is 0.36774193548387096\n",
      "Macro F1-score for Model is 0.08766852017904528\n",
      "Time to train the model: 0.5496196746826172 seconds\n",
      "F1-Score for Model is [0.         0.         0.         0.         0.         0.\n",
      " 0.08695652 0.         0.         0.62910798 0.         0.40625\n",
      " 0.         0.         0.         0.         0.17391304 0.32380952\n",
      " 0.         0.13333333]\n",
      "Precision for Model is [0.         0.         0.         0.         0.         0.\n",
      " 0.25       0.         0.         0.59292035 0.         0.34666667\n",
      " 0.         0.         0.         0.         0.5        0.28333333\n",
      " 0.         0.2       ]\n",
      "Recall for Model is [0.         0.         0.         0.         0.         0.\n",
      " 0.05263158 0.         0.         0.67       0.         0.49056604\n",
      " 0.         0.         0.         0.         0.10526316 0.37777778\n",
      " 0.         0.1       ]\n",
      "\n",
      "\n",
      "Micro F1-score for Model is 0.34868421052631576\n",
      "Macro F1-score for Model is 0.08452604768025328\n",
      "Time to train the model: 1.7643296718597412 seconds\n",
      "F1-Score for Model is [0.         0.         0.         0.         0.         0.\n",
      " 0.08333333 0.         0.         0.61682243 0.         0.36363636\n",
      " 0.         0.         0.         0.         0.23076923 0.26262626\n",
      " 0.         0.13333333]\n",
      "Precision for Model is [0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.         0.         0.57894737 0.         0.32352941\n",
      " 0.         0.         0.         0.         0.42857143 0.24074074\n",
      " 0.         0.2       ]\n",
      "Recall for Model is [0.         0.         0.         0.         0.         0.\n",
      " 0.05263158 0.         0.         0.66       0.         0.41509434\n",
      " 0.         0.         0.         0.         0.15789474 0.28888889\n",
      " 0.         0.1       ]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "for index, params in enumerate(grid, start=1):\n",
    "    evaluate_model(params, X_train, y_train, X_test, y_test, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adpt-yLsCzLSp-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a72d8dc4051dd080fc153a5760538b919c0abbb9227ab39a2d2f4f67b8d7524"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
